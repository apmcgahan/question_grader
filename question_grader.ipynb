{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c8548d8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Script to evaluate survey responses using LLM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a0fe70",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": "# INITIALIZE questions_list\n# Extract questions from the questions.docx file\nquestions_file = \"questions.docx\"\n\nif os.path.exists(questions_file):\n    doc = Document(questions_file)\n    questions_list = []\n    \n    # Extract text from each paragraph in the document\n    for paragraph in doc.paragraphs:\n        text = paragraph.text.strip()\n        # Only add non-empty lines as questions\n        if text:\n            questions_list.append(text)\n    \n    print(f\"Loaded {len(questions_list)} questions from {questions_file}\")\n    print(\"First 3 questions:\")\n    for i, q in enumerate(questions_list[:3], 1):\n        print(f\"  {i}. {q[:100]}{'...' if len(q) > 100 else ''}\")\nelse:\n    print(f\"Warning: {questions_file} not found. Using sample questions.\")\n    questions_list = [\n        \"What is your opinion on the topic?\",\n        \"How would you describe your experience?\",\n        \"What suggestions do you have for improvement?\"\n    ]\n\nprint(f\"\\nTotal questions: {len(questions_list)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98539720",
   "metadata": {},
   "outputs": [],
   "source": "import openpyxl\nfrom openpyxl import load_workbook, Workbook\n\n# INITIALIZE spreadsheet_file\n# Option 1: Create a new workbook\n# wb = Workbook()\n# ws = wb.active\n# spreadsheet_file = \"questions_spreadsheet.xlsx\"\n\n# Option 2: Load existing workbook (uncomment to use)\nspreadsheet_file = \"questions_spreadsheet.xlsx\"\ntry:\n    wb = load_workbook(spreadsheet_file)\n    ws = wb.active\n    print(f\"Loaded existing spreadsheet: {spreadsheet_file}\")\nexcept FileNotFoundError:\n    wb = Workbook()\n    ws = wb.active\n    print(f\"Created new spreadsheet: {spreadsheet_file}\")\n\n# INITIALIZE questions_list\nquestions_list = [\n    \"What is your name?\",\n    \"What is your favorite color?\",\n    \"What is your hobby?\",\n    # Add your questions here\n]\n\nprint(f\"Initialized {len(questions_list)} questions\")"
   "source": "# INITIALIZE spreadsheet_file\nimport openpyxl\nfrom openpyxl import Workbook, load_workbook\nfrom docx import Document\nimport os\n\n# Create or load the output spreadsheet\noutput_file = \"question_grader_output.xlsx\"\n\nif os.path.exists(output_file):\n    spreadsheet_file = load_workbook(output_file)\n    sheet = spreadsheet_file.active\n    print(f\"Loaded existing spreadsheet: {output_file}\")\nelse:\n    spreadsheet_file = Workbook()\n    sheet = spreadsheet_file.active\n    sheet.title = \"Graded Survey\"\n    print(f\"Created new spreadsheet: {output_file}\")\n\nprint(f\"Active sheet: {sheet.title}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb87833",
   "metadata": {},
   "outputs": [],
   "source": "# INITIALIZE llm_api_connection\n# This example uses Anthropic's Claude API\n# You can replace with OpenAI or other LLM providers\n\nfrom anthropic import Anthropic\nimport os\n\n# Initialize Anthropic client\n# Make sure to set your API key: export ANTHROPIC_API_KEY='your-key-here'\ntry:\n    anthropic_client = Anthropic(api_key=os.environ.get(\"ANTHROPIC_API_KEY\"))\n    print(\"Anthropic API client initialized\")\nexcept Exception as e:\n    print(f\"Warning: Could not initialize Anthropic client: {e}\")\n    anthropic_client = None\n\n# Alternative: OpenAI\n# from openai import OpenAI\n# openai_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2823b1fd",
   "metadata": {},
   "outputs": [],
   "source": "# Copy survey_data (rows 3 to n) from survey_spreadsheet to questions_spreadsheet\n# This assumes you have a separate survey spreadsheet with responses\n\nsurvey_spreadsheet_file = \"survey_responses.xlsx\"\n\ndef copy_survey_data(source_file, target_worksheet, start_row=3):\n    \"\"\"\n    Copy survey data from source spreadsheet to target worksheet starting at start_row.\n    \n    Args:\n        source_file: Path to the survey spreadsheet\n        target_worksheet: The target openpyxl worksheet\n        start_row: Starting row in target worksheet (default: 3)\n    \"\"\"\n    try:\n        survey_wb = load_workbook(source_file)\n        survey_ws = survey_wb.active\n        \n        # Get the dimensions of source data\n        max_row = survey_ws.max_row\n        max_col = survey_ws.max_column\n        \n        # Copy data starting from row 3 in source to start_row in target\n        row_offset = start_row - 3  # Adjust if source data starts at different row\n        \n        for row in range(3, max_row + 1):\n            for col in range(1, max_col + 1):\n                source_value = survey_ws.cell(row=row, column=col).value\n                target_worksheet.cell(row=row + row_offset, column=col, value=source_value)\n        \n        print(f\"Copied {max_row - 2} rows of survey data\")\n        survey_wb.close()\n        \n    except FileNotFoundError:\n        print(f\"Survey file '{source_file}' not found. Skipping data copy.\")\n    except Exception as e:\n        print(f\"Error copying survey data: {e}\")\n\n# Uncomment to copy survey data:\n# copy_survey_data(survey_spreadsheet_file, ws)"
   "source": "# Copy survey_data (rows 3 to n) from survey_spreadsheet to questions_spreadsheet\n# Specify the survey file that contains the original responses\nsurvey_file = \"survey_data.xlsx\"  # Change this to your actual survey file\n\nif os.path.exists(survey_file):\n    # Load the survey spreadsheet\n    survey_workbook = load_workbook(survey_file)\n    survey_sheet = survey_workbook.active\n    \n    # Get the dimensions of the survey data\n    max_row = survey_sheet.max_row\n    max_col = survey_sheet.max_column\n    \n    print(f\"Survey file: {survey_file}\")\n    print(f\"Survey sheet: {survey_sheet.title}\")\n    print(f\"Total rows in survey: {max_row}\")\n    print(f\"Copying rows 3 to {max_row}...\")\n    \n    # Copy data from row 3 onwards to the output spreadsheet\n    # Starting at row 3 in the destination as well (rows 1-2 reserved for questions and LLM answers)\n    rows_copied = 0\n    for row_idx in range(3, max_row + 1):\n        for col_idx in range(1, max_col + 1):\n            # Get value from survey sheet\n            cell_value = survey_sheet.cell(row=row_idx, column=col_idx).value\n            # Write to output sheet at the same position\n            sheet.cell(row=row_idx, column=col_idx, value=cell_value)\n        rows_copied += 1\n    \n    print(f\"Successfully copied {rows_copied} rows of survey data\")\n    \n    # Save the spreadsheet\n    spreadsheet_file.save(output_file)\n    print(f\"Saved spreadsheet to {output_file}\")\n    \nelse:\n    print(f\"Warning: Survey file '{survey_file}' not found.\")\n    print(\"Please update the 'survey_file' variable with the correct filename.\")\n    print(\"For now, creating empty spreadsheet with structure ready for data.\")"
  },
  {
   "cell_type": "markdown",
   "id": "c3d7f5d4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Step 1: Populate first row with questions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c25764b",
   "metadata": {},
   "outputs": [],
   "source": "def populate_questions(worksheet, questions_list):\n    \"\"\"\n    Populate the first row with questions from questions_list.\n    \n    Args:\n        worksheet: The openpyxl worksheet object\n        questions_list: List of question strings to populate\n    \"\"\"\n    # Start from column 1 (column A)\n    for col_index, question in enumerate(questions_list, start=1):\n        # Write each question to row 1\n        worksheet.cell(row=1, column=col_index, value=question)\n    \n    print(f\"Populated {len(questions_list)} questions in row 1\")\n    \n# Test/Example usage:\n# populate_questions(ws, questions_list)"
  },
  {
   "cell_type": "markdown",
   "id": "6cc50451",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Step 2: Generate LLM answers for each question (row 2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2774b055",
   "metadata": {},
   "outputs": [],
   "source": "def generate_llm_answers():\n    \"\"\"Generate LLM answers for each question and write to row 2\"\"\"\n    \n    # Get all values from row 1 (questions)\n    questions_row = worksheet.row_values(1)\n    \n    # Iterate through each question\n    for col_index, question in enumerate(questions_row, start=1):\n        if not question:  # Skip empty cells\n            continue\n            \n        print(f\"Generating answer for question in column {col_index}: {question[:50]}...\")\n        \n        # Create prompt for the LLM\n        prompt = f\"Answer the following question: {question}\"\n        \n        # Call the LLM API to get the answer\n        message = client.messages.create(\n            model=\"claude-3-5-sonnet-20241022\",\n            max_tokens=1024,\n            messages=[\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n        )\n        \n        # Extract the answer from the response\n        llm_answer = message.content[0].text\n        \n        # Write LLM answer to row 2 in the same column\n        worksheet.update_cell(2, col_index, llm_answer)\n        \n        print(f\"âœ“ Answer written to row 2, column {col_index}\")\n    \n    print(\"All LLM answers generated successfully!\")\n\n# Uncomment to run:\n# generate_llm_answers()"
  },
  {
   "cell_type": "markdown",
   "id": "69c1a755",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Step 3: Create evaluation columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f463e11",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(\"Question grader setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039ce408",
   "metadata": {},
   "outputs": [],
   "source": "def create_evaluation_columns():\n    \"\"\"\n    Insert evaluation columns after each question column.\n    Adds headers like Q1_evaluation, Q2_evaluation, etc.\n    \"\"\"\n    # Count the number of question columns (columns that have questions in row 1)\n    question_count = 0\n    for col in range(1, ws.max_column + 1):\n        cell_value = ws.cell(row=1, column=col).value\n        if cell_value and str(cell_value).strip():\n            question_count += 1\n    \n    print(f\"Found {question_count} questions\")\n    \n    # Insert evaluation columns after each question column\n    # Work from right to left so column positions don't shift for unprocessed questions\n    for i in range(question_count, 0, -1):\n        # Question i is at column i (before any insertions to its left)\n        question_col = i\n        evaluation_col = question_col + 1\n        \n        # Insert a new column at the evaluation position\n        ws.insert_cols(evaluation_col)\n        \n        # Add header for evaluation column\n        evaluation_header = f\"Q{i}_evaluation\"\n        ws.cell(row=1, column=evaluation_col, value=evaluation_header)\n        print(f\"Created {evaluation_header} at column {evaluation_col}\")\n    \n    print(\"Evaluation columns created successfully\")\n\n# Execute the function\ncreate_evaluation_columns()"
  },
  {
   "cell_type": "markdown",
   "id": "0606a396",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Step 4: Evaluate each human answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86922999",
   "metadata": {},
   "outputs": [],
   "source": "def evaluate_human_answers(worksheet, anthropic_client):\n    \"\"\"\n    Evaluate each human answer against the LLM's known answer.\n    \n    Args:\n        worksheet: The worksheet object containing questions and answers\n        anthropic_client: Initialized Anthropic client for API calls\n    \"\"\"\n    # Get all values from the worksheet\n    all_values = worksheet.get_all_values()\n    \n    if len(all_values) < 3:\n        print(\"Not enough rows to evaluate (need at least 3 rows)\")\n        return\n    \n    headers = all_values[0]\n    llm_answers = all_values[1]\n    \n    # Find question columns (columns without \"_evaluation\" suffix)\n    question_columns = []\n    for idx, header in enumerate(headers):\n        if header and not header.endswith('_evaluation'):\n            question_columns.append(idx)\n    \n    print(f\"Found {len(question_columns)} questions to evaluate\")\n    \n    # Iterate through all human responses (rows 3 onwards)\n    for row_idx in range(2, len(all_values)):\n        row_number = row_idx + 1  # 1-indexed for spreadsheet\n        human_responses = all_values[row_idx]\n        \n        print(f\"Evaluating row {row_number}...\")\n        \n        # Evaluate each question for this human\n        for question_num, question_col in enumerate(question_columns, start=1):\n            question_text = headers[question_col]\n            known_answer = llm_answers[question_col]\n            \n            # Get human answer\n            if question_col < len(human_responses):\n                human_answer = human_responses[question_col]\n            else:\n                human_answer = \"\"\n            \n            # Skip if human answer is empty\n            if not human_answer or human_answer.strip() == \"\":\n                print(f\"  Q{question_num}: Skipping (no answer)\")\n                continue\n            \n            # Construct evaluation prompt\n            evaluation_prompt = f\"\"\"Question: {question_text}\nKnown correct answer: {known_answer}\nHuman answer to evaluate: {human_answer}\n\nPlease evaluate the human answer compared to the known answer.\nProvide a review including:\n- Accuracy assessment\n- Key points covered or missed\n- Overall quality rating\"\"\"\n            \n            try:\n                # Get LLM evaluation using Anthropic API\n                message = anthropic_client.messages.create(\n                    model=\"claude-3-5-sonnet-20241022\",\n                    max_tokens=1024,\n                    messages=[\n                        {\"role\": \"user\", \"content\": evaluation_prompt}\n                    ]\n                )\n                \n                evaluation_result = message.content[0].text\n                \n                # Write evaluation to the column right after the question column\n                evaluation_col = question_col + 1\n                # Convert to A1 notation (1-indexed)\n                cell_address = f\"{chr(65 + evaluation_col)}{row_number}\"\n                worksheet.update(cell_address, evaluation_result)\n                \n                print(f\"  Q{question_num}: Evaluated and written to {cell_address}\")\n                \n            except Exception as e:\n                error_message = f\"Error evaluating: {str(e)}\"\n                print(f\"  Q{question_num}: {error_message}\")\n                # Write error to evaluation column\n                evaluation_col = question_col + 1\n                cell_address = f\"{chr(65 + evaluation_col)}{row_number}\"\n                worksheet.update(cell_address, error_message)\n    \n    print(\"Human answer evaluation complete!\")"
  },
  {
   "cell_type": "markdown",
   "id": "e50038c6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Main execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c4516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION main():\n",
    "#     # Step 1: Set up questions\n",
    "#     populate_questions()\n",
    "    \n",
    "#     # Step 2: Get LLM answers\n",
    "#     generate_llm_answers()\n",
    "    \n",
    "#     # Step 3: Create evaluation columns\n",
    "#     create_evaluation_columns()\n",
    "    \n",
    "#     # Step 4: Evaluate all human answers\n",
    "#     evaluate_human_answers()\n",
    "    \n",
    "#     # Save spreadsheet\n",
    "#     save_spreadsheet()\n",
    "    \n",
    "#     PRINT \"Evaluation complete!\"\n",
    "# END FUNCTION\n",
    "\n",
    "# # Run the script\n",
    "# main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}